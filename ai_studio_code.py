import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import re
import io
import chardet
from datetime import date, datetime
import urllib3
import yfinance as yf
import time

# -------------------------------------------
# 1. åŸºç¤è¨­å®š
# -------------------------------------------
st.set_page_config(page_title="å°è‚¡ ETF æˆ°æƒ…å®¤ (å…¨æ–¹ä½ç‰ˆ)", layout="wide")
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
}

# -------------------------------------------
# 2. æ•¸æ“šæŠ“å–æ ¸å¿ƒ (æ“´å……ç‰ˆ)
# -------------------------------------------

@st.cache_data(ttl=3600)
def fetch_taifex_rankings(limit=200):
    """æŠ“å–æœŸäº¤æ‰€å¸‚å€¼æ’å (æ“´å¤§åˆ° 200 åä»¥æ¶µè“‹ä¸­å‹è‚¡)"""
    url = "https://www.taifex.com.tw/cht/9/futuresQADetail"
    try:
        resp = requests.get(url, headers=HEADERS, timeout=20)
        resp.raise_for_status()
        encoding = chardet.detect(resp.content)["encoding"] or resp.apparent_encoding
        html_text = resp.content.decode(encoding, errors="ignore")
        soup = BeautifulSoup(html_text, "lxml")
        rows = []
        for tr in soup.find_all("tr"):
            tds = tr.find_all("td")
            if not tds: continue
            rank, code, name = None, None, None
            txts = [td.get_text(strip=True) for td in tds]
            for s in txts:
                if rank is None and re.fullmatch(r"\d+", s): rank = int(s)
                elif rank and not code and re.fullmatch(r"\d{4}", s): code = s
                elif rank and code and not name and not re.fullmatch(r"\d+", s):
                    name = s; break
            if rank and code and name: rows.append({"æ’å": rank, "è‚¡ç¥¨ä»£ç¢¼": code, "è‚¡ç¥¨åç¨±": name})
        
        if not rows: # Fallback
            dfs = pd.read_html(io.StringIO(html_text), flavor=["lxml", "html5lib"])
            for df in dfs:
                cols = "".join([str(c) for c in df.columns])
                if "æ’å" in cols and ("åç¨±" in cols or "ä»£è™Ÿ" in cols):
                    df.columns = [str(c).replace(" ", "") for c in df.columns]
                    col_map = {c: ("æ’å" if "æ’å" in c else "è‚¡ç¥¨ä»£ç¢¼" if "ä»£" in c else "è‚¡ç¥¨åç¨±") for c in df.columns if any(x in c for x in ["æ’å","ä»£","å"])}
                    df = df.rename(columns=col_map)
                    df = df[pd.to_numeric(df["æ’å"], errors='coerce').notnull()]
                    df["æ’å"] = df["æ’å"].astype(int)
                    df["è‚¡ç¥¨ä»£ç¢¼"] = df["è‚¡ç¥¨ä»£ç¢¼"].astype(str).str.extract(r'(\d{4})')[0]
                    return df.sort_values("æ’å").head(limit)
        return pd.DataFrame(rows).sort_values("æ’å").head(limit)
    except Exception as e:
        st.error(f"æŠ“å–å¸‚å€¼æ’åå¤±æ•—: {e}"); return pd.DataFrame()

@st.cache_data(ttl=3600)
def fetch_msci_list():
    url = "https://stock.capital.com.tw/z/zm/zmd/zmdc.djhtm?MSCI=0"
    try:
        resp = requests.get(url, headers=HEADERS, timeout=20, verify=False)
        guess = chardet.detect(resp.content)
        encoding = guess['encoding'] if guess['encoding'] else 'cp950'
        html_text = resp.content.decode(encoding, errors="ignore")
        codes = set(re.findall(r"Link2Stk\('(\d{4})'\)", html_text))
        if not codes: codes = set(re.findall(r"\b(\d{4})\b", BeautifulSoup(html_text, "lxml").get_text()))
        return sorted(list(codes))
    except: return []

@st.cache_data(ttl=3600)
def fetch_etf_holdings(etf_code="0050"):
    """é€šç”¨ ETF æˆåˆ†è‚¡æŠ“å– (0050, 0056, 00878, 00919)"""
    url = f"https://www.moneydj.com/ETF/X/Basic/Basic0007a.xdjhtm?etfid={etf_code}.TW"
    try:
        # åŠ ä¸Šéš¨æ©Ÿå»¶é²é¿å…è¢«æ“‹
        time.sleep(0.5)
        resp = requests.get(url, headers=HEADERS, timeout=20, verify=False)
        resp.encoding = resp.apparent_encoding or "utf-8"
        dfs = pd.read_html(io.StringIO(resp.text), flavor="lxml")
        names = []
        for df in dfs:
            cols = [str(c[-1] if isinstance(df.columns, pd.MultiIndex) else c).strip() for c in df.columns]
            df.columns = cols
            target = next((c for c in cols if "åç¨±" in c), None)
            if target: names.extend(df[target].astype(str).str.strip().tolist())
        
        clean_names = list(set([n for n in names if n not in ['nan','']]))
        return clean_names
    except: return []

@st.cache_data(ttl=300)
def get_advanced_stock_info(codes):
    """å–å¾—é‡åƒ¹è³‡è¨Š (å«æ¼²è·Œã€å‡é‡åˆ¤æ–·)"""
    if not codes: return {}
    try:
        tickers = " ".join([f"{c}.TW" for c in codes])
        data = yf.Tickers(tickers)
        res = {}
        for c in codes:
            try:
                t = data.tickers[f"{c}.TW"]
                h = t.history(period="5d")
                if not h.empty:
                    curr_price = h["Close"].iloc[-1]
                    prev_price = h["Close"].iloc[-2] if len(h) > 1 else curr_price
                    vol = h["Volume"].iloc[-1]
                    avg_vol = h["Volume"].mean()
                    
                    change_pct = ((curr_price - prev_price) / prev_price) * 100
                    
                    # é‡èƒ½è¨Šè™Ÿ
                    if vol > (avg_vol * 2) and vol > 1000:
                        vol_status = "ğŸ”¥çˆ†é‡"
                    elif vol < (avg_vol * 0.6):
                        vol_status = "ğŸ’§ç¸®é‡"
                    else:
                        vol_status = "â–æ­£å¸¸"
                    
                    res[c] = {
                        "ç¾åƒ¹": f"{curr_price:.2f}",
                        "æ¼²è·Œ": f"{change_pct:+.2f}%",
                        "é‡èƒ½": f"{int(vol/1000)}å¼µ ({vol_status})",
                        "raw_vol": vol,
                        "raw_change": change_pct
                    }
                else:
                    res[c] = {"ç¾åƒ¹": "-", "æ¼²è·Œ": "-", "é‡èƒ½": "-", "raw_vol": 0, "raw_change": 0}
            except:
                res[c] = {"ç¾åƒ¹": "-", "æ¼²è·Œ": "-", "é‡èƒ½": "-", "raw_vol": 0, "raw_change": 0}
        return res
    except: return {}

# -------------------------------------------
# 3. ä»‹é¢è¼”åŠ©å‡½å¼
# -------------------------------------------
def enrich_df(df, codes_list):
    if df.empty: return df
    info = get_advanced_stock_info(codes_list)
    df["ç¾åƒ¹"] = df["è‚¡ç¥¨ä»£ç¢¼"].map(lambda x: info.get(x, {}).get("ç¾åƒ¹", "-"))
    df["æ¼²è·Œå¹…"] = df["è‚¡ç¥¨ä»£ç¢¼"].map(lambda x: info.get(x, {}).get("æ¼²è·Œ", "-"))
    df["é‡èƒ½ç‹€æ…‹"] = df["è‚¡ç¥¨ä»£ç¢¼"].map(lambda x: info.get(x, {}).get("é‡èƒ½", "-"))
    return df

def get_high_yield_schedule():
    """é«˜è‚¡æ¯è¡Œäº‹æ›†"""
    m = date.today().month
    schedules = [
        {"name": "00878 (åœ‹æ³°)", "adj": [5, 11], "desc": "çœ‹é‡ ESG èˆ‡éå»é…æ¯"},
        {"name": "0056 (å…ƒå¤§)",  "adj": [6, 12], "desc": "é æ¸¬æœªä¾†ä¸€å¹´æ®–åˆ©ç‡"},
        {"name": "00919 (ç¾¤ç›Š)", "adj": [5, 12], "desc": "ç²¾æº–é«˜æ¯ (çœ‹å·²å®£å‘Š)"}
    ]
    active = [s for s in schedules if m in s["adj"]]
    return active, schedules

# -------------------------------------------
# 4. ä¸»ç¨‹å¼
# -------------------------------------------
st.title("ğŸ“ˆ å°è‚¡ ETF æˆ°æƒ…å®¤ (å…¨æ–¹ä½ç‰ˆ)")
st.caption("æ¶µè“‹ï¼š0050 (æ¬Šå€¼) | MSCI (å¤–è³‡) | 00878/0056/00919 (é«˜è‚¡æ¯ä¸­å‹)")

# --- è³‡æ–™æº–å‚™ ---
with st.spinner("æ­£åœ¨æƒæå…¨å¸‚å ´èˆ‡å„å¤§ ETF æŒè‚¡..."):
    df_mcap = fetch_taifex_rankings(limit=200)
    msci_codes = fetch_msci_list()
    
    # æŠ“å–å„å¤§ ETF æˆåˆ†è‚¡ (ç”¨ä¾†æ¨™è¨˜)
    holdings = {}
    for etf in ["0050", "0056", "00878", "00919"]:
        holdings[etf] = set(fetch_etf_holdings(etf))

    if df_mcap.empty:
        st.error("ç„¡æ³•å–å¾—å¸‚å€¼æ’å"); st.stop()

# --- å´é‚Šæ¬„ ---
with st.sidebar:
    st.header("ğŸ—“ï¸ èª¿æ•´è¡Œäº‹æ›†")
    active_hy, all_hy = get_high_yield_schedule()
    
    if active_hy:
        st.error(f"ğŸ”¥ æœ¬æœˆ ({date.today().month}æœˆ) é‡é»æˆ°å ´")
        for h in active_hy:
            st.write(f"â— **{h['name']}**")
    else:
        st.info(f"æœ¬æœˆ ({date.today().month}æœˆ) ç„¡å¤§å‹é«˜è‚¡æ¯èª¿æ•´")
        st.markdown("**ä¸‹æ³¢é å‘Šï¼š**")
        st.text("12æœˆ: 0056, 00919")
        
    st.divider()
    st.write("**è³‡æ–™æœ€å¾Œæ›´æ–°:**", datetime.now().strftime("%H:%M"))
    if st.button("ğŸ”„ æ›´æ–°è¡Œæƒ…"):
        st.cache_data.clear()
        st.rerun()

# --- åˆ†é  ---
tab1, tab2, tab3 = st.tabs(["ğŸ‡¹ğŸ‡¼ 0050 æ¬Šå€¼å°æ±º", "ğŸŒ MSCI å¤–è³‡å°æ±º", "ğŸ’° é«˜è‚¡æ¯/ä¸­å‹ 100"])

# ==================================================
# Tab 1: 0050 (æ˜ç¢ºç´å…¥ vs å‰”é™¤)
# ==================================================
with tab1:
    st.markdown("### 0050 èª¿æ•´é æ¸¬ (å¸‚å€¼å‰ 50 å¤§)")
    if holdings["0050"]:
        df_anl = df_mcap.head(100).copy()
        df_anl["in_0050"] = df_anl["è‚¡ç¥¨åç¨±"].isin(holdings["0050"])
        
        # 1. ç´å…¥å€™é¸ (Rank <= 40 or 41-50)
        must_in = df_anl[(df_anl["æ’å"] <= 40) & (~df_anl["in_0050"])]
        candidate_in = df_anl[(df_anl["æ’å"] > 40) & (df_anl["æ’å"] <= 50) & (~df_anl["in_0050"])]
        
        # 2. å‰”é™¤å€™é¸ (Rank > 60 or 41-60)
        # éœ€å¾å®Œæ•´æ¸…å–®æ‰¾åœ¨ 0050 å…§çš„äºº
        in_list = df_mcap[df_mcap["è‚¡ç¥¨åç¨±"].isin(holdings["0050"])]
        must_out = in_list[in_list["æ’å"] > 60]
        danger_out = in_list[(in_list["æ’å"] > 40) & (in_list["æ’å"] <= 60)].sort_values("æ’å", ascending=False)
        
        # æº–å‚™æŠ“è¡Œæƒ…
        codes = list(must_in["è‚¡ç¥¨ä»£ç¢¼"]) + list(candidate_in["è‚¡ç¥¨ä»£ç¢¼"]) + list(must_out["è‚¡ç¥¨ä»£ç¢¼"]) + list(danger_out["è‚¡ç¥¨ä»£ç¢¼"])
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.success("ğŸŸ¢ **æ½›åœ¨ç´å…¥å€ (è²·é€²è¨Šè™Ÿ)**")
            if not must_in.empty:
                st.markdown("**ğŸ”¥ å¿…ç„¶ç´å…¥ (æ’å â‰¤ 40)**")
                st.dataframe(enrich_df(must_in, codes)[["æ’å","è‚¡ç¥¨åç¨±","ç¾åƒ¹","æ¼²è·Œå¹…","é‡èƒ½ç‹€æ…‹"]], hide_index=True)
            
            if not candidate_in.empty:
                st.markdown("**âš”ï¸ é—œéµæŒ‘æˆ°è€… (æ’å 41-50)**")
                st.dataframe(enrich_df(candidate_in, codes)[["æ’å","è‚¡ç¥¨åç¨±","ç¾åƒ¹","æ¼²è·Œå¹…","é‡èƒ½ç‹€æ…‹"]], hide_index=True)
            
            if must_in.empty and candidate_in.empty:
                st.info("å‰ 50 åçš†å·²åœ¨åå–®å…§ï¼Œç„¡æ½›åœ¨ç´å…¥è€…ã€‚")

        with col2:
            st.error("ğŸ”´ **æ½›åœ¨å‰”é™¤å€ (è³£å‡ºè¨Šè™Ÿ)**")
            if not must_out.empty:
                st.markdown("**ğŸ‘‹ å¿…ç„¶å‰”é™¤ (æ’å > 60)**")
                st.dataframe(enrich_df(must_out, codes)[["æ’å","è‚¡ç¥¨åç¨±","ç¾åƒ¹","æ¼²è·Œå¹…","é‡èƒ½ç‹€æ…‹"]], hide_index=True)
                
            if not danger_out.empty:
                st.markdown("**âš ï¸ å±éšªé‚Šç·£ (æ’å 41-60)**")
                st.dataframe(enrich_df(danger_out, codes)[["æ’å","è‚¡ç¥¨åç¨±","ç¾åƒ¹","æ¼²è·Œå¹…","é‡èƒ½ç‹€æ…‹"]], hide_index=True)

    else:
        st.warning("ç„¡æ³•å–å¾— 0050 æˆåˆ†è‚¡")

# ==================================================
# Tab 2: MSCI (æ˜ç¢ºç´å…¥ vs å‰”é™¤)
# ==================================================
with tab2:
    st.markdown("### MSCI èª¿æ•´é æ¸¬ (å¸‚å€¼å‰ 100 å¤§)")
    if msci_codes:
        # 1. ç´å…¥ (Rank <= 85)
        prob_in = df_mcap[(df_mcap["æ’å"] <= 85) & (~df_mcap["è‚¡ç¥¨ä»£ç¢¼"].isin(msci_codes))]
        watch_in = df_mcap[(df_mcap["æ’å"] > 85) & (df_mcap["æ’å"] <= 100) & (~df_mcap["è‚¡ç¥¨ä»£ç¢¼"].isin(msci_codes))]
        
        # 2. å‰”é™¤ (Rank > 100)
        prob_out = df_mcap[(df_mcap["æ’å"] > 100) & (df_mcap["è‚¡ç¥¨ä»£ç¢¼"].isin(msci_codes))]
        
        codes = list(prob_in["è‚¡ç¥¨ä»£ç¢¼"]) + list(watch_in["è‚¡ç¥¨ä»£ç¢¼"]) + list(prob_out["è‚¡ç¥¨ä»£ç¢¼"])
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.success("ğŸŸ¢ **æ½›åœ¨ç´å…¥å€ (å¤–è³‡è²·ç›¤)**")
            if not prob_in.empty:
                st.markdown("**ğŸ”¥ é«˜æ©Ÿç‡ç´å…¥ (æ’å â‰¤ 85)**")
                st.dataframe(enrich_df(prob_in, codes)[["æ’å","è‚¡ç¥¨åç¨±","ç¾åƒ¹","æ¼²è·Œå¹…","é‡èƒ½ç‹€æ…‹"]], hide_index=True)
            else:
                st.write("å‰ 85 åçš†å·²ç´å…¥ã€‚")
                
            if not watch_in.empty:
                st.markdown("**ğŸ§ é‚Šç·£è§€å¯Ÿ (æ’å 86-100)**")
                st.dataframe(enrich_df(watch_in, codes)[["æ’å","è‚¡ç¥¨åç¨±","ç¾åƒ¹","æ¼²è·Œå¹…","é‡èƒ½ç‹€æ…‹"]], hide_index=True)

        with col2:
            st.error("ğŸ”´ **æ½›åœ¨å‰”é™¤å€ (å¤–è³‡è³£ç›¤)**")
            if not prob_out.empty:
                st.markdown("**ğŸ‘‹ æ½›åœ¨å‰”é™¤ (æ’å > 100)**")
                st.dataframe(enrich_df(prob_out, codes)[["æ’å","è‚¡ç¥¨åç¨±","ç¾åƒ¹","æ¼²è·Œå¹…","é‡èƒ½ç‹€æ…‹"]], hide_index=True)
            else:
                st.write("ç›®å‰æˆåˆ†è‚¡æ’åçš†åœ¨ 100 åå…§ã€‚")
    else:
        st.warning("ç„¡æ³•å–å¾— MSCI åå–®")

# ==================================================
# Tab 3: é«˜è‚¡æ¯/ä¸­å‹ 100 (æ–°å¢åŠŸèƒ½)
# ==================================================
with tab3:
    st.markdown("""
    ### ğŸ’° é«˜è‚¡æ¯/ä¸­å‹è‚¡æˆ°å ´ (00878, 0056, 00919)
    **é‚è¼¯ï¼š** é€™äº› ETF ä¸»è¦å¾ **å¸‚å€¼å‰ 150 å¤§** çš„è‚¡ç¥¨ä¸­ï¼ŒæŒ‘é¸æ®–åˆ©ç‡é«˜çš„ã€‚
    **ç­–ç•¥ï¼š** é—œæ³¨æ’å **50~150 å** çš„è‚¡ç¥¨ã€‚è‹¥è©²æœˆæœ‰ ETF èª¿æ•´ï¼Œä¸”æŸæª”è‚¡ç¥¨**æˆäº¤é‡æ”¾å¤§ã€è‚¡åƒ¹ä¸Šæ¼²**ï¼Œæ¥µå¯èƒ½æ˜¯è¢«ç´å…¥çš„ç›®æ¨™ã€‚
    """)
    
    # 1. ç¯©é¸ä¸­å‹è‚¡ (Rank 50-150)
    mid_cap = df_mcap[(df_mcap["æ’å"] >= 50) & (df_mcap["æ’å"] <= 150)].copy()
    
    # 2. æ¨™è¨˜ç›®å‰æ˜¯å¦å·²åœ¨é€™äº› ETF ä¸­ (é¿å…é‡è¤‡æ¨è–¦)
    def check_status(name):
        tags = []
        if name in holdings["0056"]: tags.append("0056")
        if name in holdings["00878"]: tags.append("00878")
        if name in holdings["00919"]: tags.append("00919")
        return ", ".join(tags) if tags else "-"
    
    mid_cap["å·²å…¥é¸ ETF"] = mid_cap["è‚¡ç¥¨åç¨±"].apply(check_status)
    
    # 3. å–å¾—è¡Œæƒ…
    codes = list(mid_cap["è‚¡ç¥¨ä»£ç¢¼"])
    info = get_advanced_stock_info(codes)
    
    # 4. æ•´åˆè³‡æ–™
    mid_cap["ç¾åƒ¹"] = mid_cap["è‚¡ç¥¨ä»£ç¢¼"].map(lambda x: info.get(x, {}).get("ç¾åƒ¹", "-"))
    mid_cap["æ¼²è·Œå¹…"] = mid_cap["è‚¡ç¥¨ä»£ç¢¼"].map(lambda x: info.get(x, {}).get("æ¼²è·Œ", "-"))
    mid_cap["é‡èƒ½ç‹€æ…‹"] = mid_cap["è‚¡ç¥¨ä»£ç¢¼"].map(lambda x: info.get(x, {}).get("é‡èƒ½", "-"))
    mid_cap["raw_vol"] = mid_cap["è‚¡ç¥¨ä»£ç¢¼"].map(lambda x: info.get(x, {}).get("raw_vol", 0))
    mid_cap["raw_change"] = mid_cap["è‚¡ç¥¨ä»£ç¢¼"].map(lambda x: info.get(x, {}).get("raw_change", 0))

    # 5. ç¯©é¸å™¨ (äº’å‹•åŠŸèƒ½)
    c1, c2 = st.columns([1, 2])
    with c1:
        filter_type = st.radio("ç¯©é¸é‡é»ï¼š", ["ğŸ”¥ é‡èƒ½çˆ†ç™¼ (æœ‰äººåœ¨è²·)", "ğŸš€ è‚¡åƒ¹å¼·å‹¢ (æ¼²å¹…é«˜)", "ğŸ’ å°šæœªå…¥é¸ (æ½›åœ¨é»‘é¦¬)"])
    
    with c2:
        st.info("ğŸ’¡ æç¤ºï¼šæ‰¾ã€Œé‡èƒ½çˆ†ç™¼ã€ä¸”ã€Œå°šæœªå…¥é¸ã€çš„è‚¡ç¥¨ï¼Œé…åˆè©²è‚¡æ®–åˆ©ç‡(éœ€å¦æŸ¥)ï¼Œå‘½ä¸­ç‡æœ€é«˜ã€‚")

    # æ ¹æ“šç¯©é¸é¡¯ç¤º
    if filter_type == "ğŸ”¥ é‡èƒ½çˆ†ç™¼ (æœ‰äººåœ¨è²·)":
        # æ‰¾æˆäº¤é‡å¤§æ–¼ 0 ä¸”ä¾é‡æ’åº
        display_df = mid_cap.sort_values("raw_vol", ascending=False).head(20)
    elif filter_type == "ğŸš€ è‚¡åƒ¹å¼·å‹¢ (æ¼²å¹…é«˜)":
        display_df = mid_cap.sort_values("raw_change", ascending=False).head(20)
    else:
        # æ‰¾é‚„æ²’è¢«é€™ä¸‰æª” ETF é¸ä¸­ï¼Œä¸”æ’åé å‰çš„
        display_df = mid_cap[mid_cap["å·²å…¥é¸ ETF"] == "-"].sort_values("æ’å").head(20)

    st.dataframe(
        display_df[["æ’å", "è‚¡ç¥¨åç¨±", "å·²å…¥é¸ ETF", "ç¾åƒ¹", "æ¼²è·Œå¹…", "é‡èƒ½ç‹€æ…‹"]],
        use_container_width=True,
        hide_index=True
    )
