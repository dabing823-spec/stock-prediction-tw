import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import re
import io
import chardet
from datetime import date, datetime
import urllib3
import yfinance as yf
import time

# -------------------------------------------
# 1. åŸºç¤è¨­å®š
# -------------------------------------------
st.set_page_config(page_title="å°è‚¡ ETF æˆ°æƒ…å®¤ (Pro)", layout="wide")
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
}

# -------------------------------------------
# 2. æ•¸æ“šæŠ“å–æ ¸å¿ƒ
# -------------------------------------------

@st.cache_data(ttl=3600)
def fetch_taifex_rankings(limit=200):
    url = "https://www.taifex.com.tw/cht/9/futuresQADetail"
    try:
        resp = requests.get(url, headers=HEADERS, timeout=20)
        resp.raise_for_status()
        encoding = chardet.detect(resp.content)["encoding"] or resp.apparent_encoding
        html_text = resp.content.decode(encoding, errors="ignore")
        soup = BeautifulSoup(html_text, "lxml")
        rows = []
        for tr in soup.find_all("tr"):
            tds = tr.find_all("td")
            if not tds: continue
            rank, code, name = None, None, None
            txts = [td.get_text(strip=True) for td in tds]
            for s in txts:
                if rank is None and re.fullmatch(r"\d+", s): rank = int(s)
                elif rank and not code and re.fullmatch(r"\d{4}", s): code = s
                elif rank and code and not name and not re.fullmatch(r"\d+", s):
                    name = s; break
            if rank and code and name: rows.append({"æ’å": rank, "è‚¡ç¥¨ä»£ç¢¼": code, "è‚¡ç¥¨åç¨±": name})
        
        if not rows:
            dfs = pd.read_html(io.StringIO(html_text), flavor=["lxml", "html5lib"])
            for df in dfs:
                cols = "".join([str(c) for c in df.columns])
                if "æ’å" in cols and ("åç¨±" in cols or "ä»£è™Ÿ" in cols):
                    df.columns = [str(c).replace(" ", "") for c in df.columns]
                    col_map = {c: ("æ’å" if "æ’å" in c else "è‚¡ç¥¨ä»£ç¢¼" if "ä»£" in c else "è‚¡ç¥¨åç¨±") for c in df.columns if any(x in c for x in ["æ’å","ä»£","å"])}
                    df = df.rename(columns=col_map)
                    df = df[pd.to_numeric(df["æ’å"], errors='coerce').notnull()]
                    df["æ’å"] = df["æ’å"].astype(int)
                    df["è‚¡ç¥¨ä»£ç¢¼"] = df["è‚¡ç¥¨ä»£ç¢¼"].astype(str).str.extract(r'(\d{4})')[0]
                    return df.sort_values("æ’å").head(limit)
        return pd.DataFrame(rows).sort_values("æ’å").head(limit)
    except Exception as e:
        st.error(f"æŠ“å–å¸‚å€¼æ’åå¤±æ•—: {e}"); return pd.DataFrame()

@st.cache_data(ttl=3600)
def fetch_msci_list():
    url = "https://stock.capital.com.tw/z/zm/zmd/zmdc.djhtm?MSCI=0"
    try:
        resp = requests.get(url, headers=HEADERS, timeout=20, verify=False)
        guess = chardet.detect(resp.content)
        encoding = guess['encoding'] if guess['encoding'] else 'cp950'
        html_text = resp.content.decode(encoding, errors="ignore")
        codes = set(re.findall(r"Link2Stk\('(\d{4})'\)", html_text))
        if not codes: codes = set(re.findall(r"\b(\d{4})\b", BeautifulSoup(html_text, "lxml").get_text()))
        return sorted(list(codes))
    except: return []

@st.cache_data(ttl=3600)
def fetch_etf_holdings(etf_code="0050"):
    url = f"https://www.moneydj.com/ETF/X/Basic/Basic0007a.xdjhtm?etfid={etf_code}.TW"
    try:
        time.sleep(0.5)
        resp = requests.get(url, headers=HEADERS, timeout=20, verify=False)
        resp.encoding = resp.apparent_encoding or "utf-8"
        dfs = pd.read_html(io.StringIO(resp.text), flavor="lxml")
        names = []
        for df in dfs:
            cols = [str(c[-1] if isinstance(df.columns, pd.MultiIndex) else c).strip() for c in df.columns]
            df.columns = cols
            target = next((c for c in cols if "åç¨±" in c), None)
            if target: names.extend(df[target].astype(str).str.strip().tolist())
        clean_names = list(set([n for n in names if n not in ['nan','']]))
        return clean_names
    except: return []

@st.cache_data(ttl=300)
def get_advanced_stock_info(codes):
    """å–å¾—é‡åƒ¹è³‡è¨Š (å«æˆäº¤å€¼è¨ˆç®—)"""
    if not codes: return {}
    try:
        tickers = " ".join([f"{c}.TW" for c in codes])
        data = yf.Tickers(tickers)
        res = {}
        for c in codes:
            try:
                t = data.tickers[f"{c}.TW"]
                h = t.history(period="5d")
                if not h.empty:
                    curr_price = h["Close"].iloc[-1]
                    prev_price = h["Close"].iloc[-2] if len(h) > 1 else curr_price
                    vol = h["Volume"].iloc[-1]
                    avg_vol = h["Volume"].mean()
                    
                    # è¨ˆç®—æˆäº¤å€¼ (åƒ¹æ ¼ * æˆäº¤é‡)
                    turnover = curr_price * vol
                    
                    # æ ¼å¼åŒ–æˆäº¤å€¼
                    if turnover > 100000000:
                        turnover_str = f"{turnover/100000000:.1f}å„„"
                    else:
                        turnover_str = f"{turnover/10000:.0f}è¬"
                    
                    change_pct = ((curr_price - prev_price) / prev_price) * 100
                    
                    # é‡èƒ½è¨Šè™Ÿ
                    if vol > (avg_vol * 2) and vol > 1000:
                        vol_status = "ğŸ”¥çˆ†é‡"
                    elif vol < (avg_vol * 0.6):
                        vol_status = "ğŸ’§ç¸®é‡"
                    else:
                        vol_status = "â–æ­£å¸¸"
                    
                    res[c] = {
                        "ç¾åƒ¹": f"{curr_price:.2f}",
                        "æ¼²è·Œ": f"{change_pct:+.2f}%",
                        "é‡èƒ½": f"{int(vol/1000)}å¼µ ({vol_status})",
                        "æˆäº¤å€¼": turnover_str,
                        "raw_vol": vol,
                        "raw_change": change_pct,
                        "raw_turnover": turnover
                    }
                else:
                    res[c] = {"ç¾åƒ¹": "-", "æ¼²è·Œ": "-", "é‡èƒ½": "-", "æˆäº¤å€¼": "-", "raw_vol": 0, "raw_change": 0, "raw_turnover": 0}
            except:
                res[c] = {"ç¾åƒ¹": "-", "æ¼²è·Œ": "-", "é‡èƒ½": "-", "æˆäº¤å€¼": "-", "raw_vol": 0, "raw_change": 0, "raw_turnover": 0}
        return res
    except: return {}

# -------------------------------------------
# 3. ä»‹é¢è¼”åŠ©å‡½å¼
# -------------------------------------------
def enrich_df(df, codes_list):
    if df.empty: return df
    info = get_advanced_stock_info(codes_list)
    df["ç¾åƒ¹"] = df["è‚¡ç¥¨ä»£ç¢¼"].map(lambda x: info.get(x, {}).get("ç¾åƒ¹", "-"))
    df["æ¼²è·Œå¹…"] = df["è‚¡ç¥¨ä»£ç¢¼"].map(lambda x: info.get(x, {}).get("æ¼²è·Œ", "-"))
    df["æˆäº¤é‡"] = df["è‚¡ç¥¨ä»£ç¢¼"].map(lambda x: info.get(x, {}).get("é‡èƒ½", "-"))
    df["æˆäº¤å€¼"] = df["è‚¡ç¥¨ä»£ç¢¼"].map(lambda x: info.get(x, {}).get("æˆäº¤å€¼", "-"))
    
    # éš±è—æ’åºç”¨çš„ raw dataï¼Œä½†ä¿ç•™åœ¨ DataFrame ä¸­
    df["raw_turnover"] = df["è‚¡ç¥¨ä»£ç¢¼"].map(lambda x: info.get(x, {}).get("raw_turnover", 0))
    
    # å»ºç«‹ Yahoo é€£çµ (ä¹‹å¾Œç”¨ column_config æ¸²æŸ“)
    df["é€£çµä»£ç¢¼"] = df["è‚¡ç¥¨ä»£ç¢¼"].apply(lambda x: f"https://tw.stock.yahoo.com/quote/{x}")
    return df

def get_high_yield_schedule():
    m = date.today().month
    schedules = [
        {"name": "00878 (åœ‹æ³°)", "adj": [5, 11]},
        {"name": "0056 (å…ƒå¤§)",  "adj": [6, 12]},
        {"name": "00919 (ç¾¤ç›Š)", "adj": [5, 12]}
    ]
    active = [s for s in schedules if m in s["adj"]]
    return active

# é¡¯ç¤ºè¨­å®š (å…±ç”¨)
column_cfg = {
    "é€£çµä»£ç¢¼": st.column_config.LinkColumn(
        "ä»£è™Ÿ", 
        display_text=r"https://tw\.stock\.yahoo\.com/quote/(\d+)", # Regex æå–ä»£ç¢¼é¡¯ç¤º
        help="é»æ“ŠæŸ¥çœ‹ Yahoo å€‹è‚¡è³‡è¨Š"
    ),
    "raw_turnover": None, # éš±è—
    "raw_vol": None,
    "raw_change": None
}

# -------------------------------------------
# 4. ä¸»ç¨‹å¼
# -------------------------------------------
st.title("ğŸ“ˆ å°è‚¡ ETF æˆ°æƒ…å®¤ (Pro)")
st.caption("é»æ“Šä»£è™Ÿå¯é€£çµè‡³ Yahoo è‚¡å¸‚ | æ¶µè“‹ 0050, MSCI, é«˜è‚¡æ¯ä¸­å‹è‚¡")

with st.spinner("æ­£åœ¨æƒæå…¨å¸‚å ´é‡åƒ¹èˆ‡è³‡é‡‘æµå‘..."):
    df_mcap = fetch_taifex_rankings(limit=200)
    msci_codes = fetch_msci_list()
    
    holdings = {}
    for etf in ["0050", "0056", "00878", "00919"]:
        holdings[etf] = set(fetch_etf_holdings(etf))

    if df_mcap.empty:
        st.error("ç„¡æ³•å–å¾—å¸‚å€¼æ’å"); st.stop()

# å´é‚Šæ¬„
with st.sidebar:
    st.header("ğŸ—“ï¸ èª¿æ•´è¡Œäº‹æ›†")
    active_hy = get_high_yield_schedule()
    if active_hy:
        st.error(f"ğŸ”¥ æœ¬æœˆé‡é»: {', '.join([h['name'] for h in active_hy])}")
    else:
        st.info("æœ¬æœˆç„¡å¤§å‹é«˜è‚¡æ¯èª¿æ•´")
        st.text("ä¸‹æ³¢: 12æœˆ (0056, 00919)")
    
    st.divider()
    if st.button("ğŸ”„ æ›´æ–°è¡Œæƒ…"):
        st.cache_data.clear()
        st.rerun()

tab1, tab2, tab3 = st.tabs(["ğŸ‡¹ğŸ‡¼ 0050 æ¬Šå€¼å°æ±º", "ğŸŒ MSCI å¤–è³‡å°æ±º", "ğŸ’° é«˜è‚¡æ¯/ä¸­å‹ 100"])

# ==================================================
# Tab 1: 0050
# ==================================================
with tab1:
    st.markdown("### 0050 èª¿æ•´é æ¸¬")
    if holdings["0050"]:
        df_anl = df_mcap.head(100).copy()
        df_anl["in_0050"] = df_anl["è‚¡ç¥¨åç¨±"].isin(holdings["0050"])
        
        must_in = df_anl[(df_anl["æ’å"] <= 40) & (~df_anl["in_0050"])]
        candidate_in = df_anl[(df_anl["æ’å"] > 40) & (df_anl["æ’å"] <= 50) & (~df_anl["in_0050"])]
        
        in_list = df_mcap[df_mcap["è‚¡ç¥¨åç¨±"].isin(holdings["0050"])]
        must_out = in_list[in_list["æ’å"] > 60]
        danger_out = in_list[(in_list["æ’å"] > 40) & (in_list["æ’å"] <= 60)].sort_values("æ’å", ascending=False)
        
        all_codes = list(must_in["è‚¡ç¥¨ä»£ç¢¼"]) + list(candidate_in["è‚¡ç¥¨ä»£ç¢¼"]) + list(must_out["è‚¡ç¥¨ä»£ç¢¼"]) + list(danger_out["è‚¡ç¥¨ä»£ç¢¼"])
        
        c1, c2 = st.columns(2)
        with c1:
            st.success("ğŸŸ¢ **æ½›åœ¨ç´å…¥å€**")
            if not must_in.empty:
                st.markdown("**ğŸ”¥ å¿…ç„¶ç´å…¥ (Rank â‰¤ 40)**")
                df_show = enrich_df(must_in, all_codes)
                st.dataframe(df_show[["æ’å","é€£çµä»£ç¢¼","è‚¡ç¥¨åç¨±","ç¾åƒ¹","æˆäº¤å€¼","æ¼²è·Œå¹…","æˆäº¤é‡"]], hide_index=True, column_config=column_cfg)
            
            if not candidate_in.empty:
                st.markdown("**âš”ï¸ é—œéµæŒ‘æˆ°è€… (Rank 41-50)**")
                df_show = enrich_df(candidate_in, all_codes)
                st.dataframe(df_show[["æ’å","é€£çµä»£ç¢¼","è‚¡ç¥¨åç¨±","ç¾åƒ¹","æˆäº¤å€¼","æ¼²è·Œå¹…","æˆäº¤é‡"]], hide_index=True, column_config=column_cfg)

        with c2:
            st.error("ğŸ”´ **æ½›åœ¨å‰”é™¤å€**")
            if not must_out.empty:
                st.markdown("**ğŸ‘‹ å¿…ç„¶å‰”é™¤ (Rank > 60)**")
                df_show = enrich_df(must_out, all_codes)
                st.dataframe(df_show[["æ’å","é€£çµä»£ç¢¼","è‚¡ç¥¨åç¨±","ç¾åƒ¹","æˆäº¤å€¼","æ¼²è·Œå¹…","æˆäº¤é‡"]], hide_index=True, column_config=column_cfg)
            
            if not danger_out.empty:
                st.markdown("**âš ï¸ å±éšªé‚Šç·£ (Rank 41-60)**")
                df_show = enrich_df(danger_out, all_codes)
                st.dataframe(df_show[["æ’å","é€£çµä»£ç¢¼","è‚¡ç¥¨åç¨±","ç¾åƒ¹","æˆäº¤å€¼","æ¼²è·Œå¹…","æˆäº¤é‡"]], hide_index=True, column_config=column_cfg)
    else:
        st.warning("0050 è³‡æ–™è®€å–å¤±æ•—")

# ==================================================
# Tab 2: MSCI
# ==================================================
with tab2:
    st.markdown("### MSCI èª¿æ•´é æ¸¬")
    if msci_codes:
        prob_in = df_mcap[(df_mcap["æ’å"] <= 85) & (~df_mcap["è‚¡ç¥¨ä»£ç¢¼"].isin(msci_codes))]
        watch_in = df_mcap[(df_mcap["æ’å"] > 85) & (df_mcap["æ’å"] <= 100) & (~df_mcap["è‚¡ç¥¨ä»£ç¢¼"].isin(msci_codes))]
        prob_out = df_mcap[(df_mcap["æ’å"] > 100) & (df_mcap["è‚¡ç¥¨ä»£ç¢¼"].isin(msci_codes))]
        
        all_codes = list(prob_in["è‚¡ç¥¨ä»£ç¢¼"]) + list(watch_in["è‚¡ç¥¨ä»£ç¢¼"]) + list(prob_out["è‚¡ç¥¨ä»£ç¢¼"])
        
        c1, c2 = st.columns(2)
        with c1:
            st.success("ğŸŸ¢ **æ½›åœ¨ç´å…¥å€**")
            if not prob_in.empty:
                st.markdown("**ğŸ”¥ é«˜æ©Ÿç‡ç´å…¥ (Rank â‰¤ 85)**")
                df_show = enrich_df(prob_in, all_codes)
                st.dataframe(df_show[["æ’å","é€£çµä»£ç¢¼","è‚¡ç¥¨åç¨±","ç¾åƒ¹","æˆäº¤å€¼","æ¼²è·Œå¹…","æˆäº¤é‡"]], hide_index=True, column_config=column_cfg)
            
            if not watch_in.empty:
                st.markdown("**ğŸ§ é‚Šç·£è§€å¯Ÿ (Rank 86-100)**")
                df_show = enrich_df(watch_in, all_codes)
                st.dataframe(df_show[["æ’å","é€£çµä»£ç¢¼","è‚¡ç¥¨åç¨±","ç¾åƒ¹","æˆäº¤å€¼","æ¼²è·Œå¹…","æˆäº¤é‡"]], hide_index=True, column_config=column_cfg)

        with c2:
            st.error("ğŸ”´ **æ½›åœ¨å‰”é™¤å€**")
            if not prob_out.empty:
                st.markdown("**ğŸ‘‹ æ½›åœ¨å‰”é™¤ (Rank > 100)**")
                df_show = enrich_df(prob_out, all_codes)
                st.dataframe(df_show[["æ’å","é€£çµä»£ç¢¼","è‚¡ç¥¨åç¨±","ç¾åƒ¹","æˆäº¤å€¼","æ¼²è·Œå¹…","æˆäº¤é‡"]], hide_index=True, column_config=column_cfg)
    else:
        st.warning("MSCI è³‡æ–™è®€å–å¤±æ•—")

# ==================================================
# Tab 3: é«˜è‚¡æ¯/ä¸­å‹ 100
# ==================================================
with tab3:
    st.markdown("### ğŸ’° é«˜è‚¡æ¯/ä¸­å‹è‚¡æˆ°å ´")
    st.markdown("é–å®š **å¸‚å€¼ 50~150 å**ï¼Œçµåˆ **è³‡é‡‘ç†±åº¦ (æˆäº¤å€¼)** åˆ¤æ–·ã€‚")
    
    mid_cap = df_mcap[(df_mcap["æ’å"] >= 50) & (df_mcap["æ’å"] <= 150)].copy()
    
    def check_status(name):
        tags = []
        if name in holdings["0056"]: tags.append("0056")
        if name in holdings["00878"]: tags.append("00878")
        if name in holdings["00919"]: tags.append("00919")
        return ", ".join(tags) if tags else "-"
    
    mid_cap["å·²å…¥é¸ ETF"] = mid_cap["è‚¡ç¥¨åç¨±"].apply(check_status)
    
    # æŠ“å–è¡Œæƒ…
    codes = list(mid_cap["è‚¡ç¥¨ä»£ç¢¼"])
    info = get_advanced_stock_info(codes)
    
    mid_cap["ç¾åƒ¹"] = mid_cap["è‚¡ç¥¨ä»£ç¢¼"].map(lambda x: info.get(x, {}).get("ç¾åƒ¹", "-"))
    mid_cap["æ¼²è·Œå¹…"] = mid_cap["è‚¡ç¥¨ä»£ç¢¼"].map(lambda x: info.get(x, {}).get("æ¼²è·Œ", "-"))
    mid_cap["æˆäº¤é‡"] = mid_cap["è‚¡ç¥¨ä»£ç¢¼"].map(lambda x: info.get(x, {}).get("é‡èƒ½", "-"))
    mid_cap["æˆäº¤å€¼"] = mid_cap["è‚¡ç¥¨ä»£ç¢¼"].map(lambda x: info.get(x, {}).get("æˆäº¤å€¼", "-"))
    
    # ç”¨ä¾†æ’åºçš„æ•¸å€¼
    mid_cap["raw_turnover"] = mid_cap["è‚¡ç¥¨ä»£ç¢¼"].map(lambda x: info.get(x, {}).get("raw_turnover", 0))
    mid_cap["raw_vol"] = mid_cap["è‚¡ç¥¨ä»£ç¢¼"].map(lambda x: info.get(x, {}).get("raw_vol", 0))
    mid_cap["raw_change"] = mid_cap["è‚¡ç¥¨ä»£ç¢¼"].map(lambda x: info.get(x, {}).get("raw_change", 0))
    
    # é€£çµ
    mid_cap["é€£çµä»£ç¢¼"] = mid_cap["è‚¡ç¥¨ä»£ç¢¼"].apply(lambda x: f"https://tw.stock.yahoo.com/quote/{x}")

    # ç¯©é¸èˆ‡æ’åº
    c1, c2 = st.columns([1, 2])
    with c1:
        sort_method = st.radio("æ’åºä¾æ“šï¼š", ["ğŸ’° è³‡é‡‘ç†±åº¦ (æˆäº¤å€¼)", "ğŸ”¥ é‡èƒ½çˆ†ç™¼ (æˆäº¤é‡)", "ğŸš€ è‚¡åƒ¹å¼·å‹¢ (æ¼²è·Œå¹…)", "ğŸ’ å°šæœªå…¥é¸ (æŒ–å¯¶)"])
    
    with c2:
        st.info("ğŸ’¡ é»æ“Šè¡¨æ ¼å…§çš„ã€Œä»£è™Ÿã€å¯ç›´æ¥è·³è½‰ Yahoo è‚¡å¸‚ã€‚")

    if sort_method == "ğŸ’° è³‡é‡‘ç†±åº¦ (æˆäº¤å€¼)":
        df_show = mid_cap.sort_values("raw_turnover", ascending=False).head(30)
    elif sort_method == "ğŸ”¥ é‡èƒ½çˆ†ç™¼ (æˆäº¤é‡)":
        df_show = mid_cap.sort_values("raw_vol", ascending=False).head(30)
    elif sort_method == "ğŸš€ è‚¡åƒ¹å¼·å‹¢ (æ¼²è·Œå¹…)":
        df_show = mid_cap.sort_values("raw_change", ascending=False).head(30)
    else:
        df_show = mid_cap[mid_cap["å·²å…¥é¸ ETF"] == "-"].sort_values("æ’å").head(30)

    st.dataframe(
        df_show[["æ’å", "é€£çµä»£ç¢¼", "è‚¡ç¥¨åç¨±", "å·²å…¥é¸ ETF", "ç¾åƒ¹", "æˆäº¤å€¼", "æ¼²è·Œå¹…", "æˆäº¤é‡"]],
        use_container_width=True,
        hide_index=True,
        column_config=column_cfg
    )
