import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import re
import io
import chardet
from datetime import date, datetime
import urllib3
import yfinance as yf

# -------------------------------------------
# 1. åŸºç¤è¨­å®šèˆ‡å·¥å…·
# -------------------------------------------
st.set_page_config(page_title="å°è‚¡æŒ‡æ•¸èª¿æ•´é æ¸¬ Pro", layout="wide")

# å¿½ç•¥ SSL è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
}

# -------------------------------------------
# 2. çˆ¬èŸ²å‡½å¼
# -------------------------------------------
@st.cache_data(ttl=3600)
def fetch_taifex_rankings(limit=200):
    """æŠ“å–æœŸäº¤æ‰€å¸‚å€¼æ’å"""
    url = "https://www.taifex.com.tw/cht/9/futuresQADetail"
    try:
        resp = requests.get(url, headers=HEADERS, timeout=20)
        resp.raise_for_status()
        encoding = chardet.detect(resp.content)["encoding"] or resp.apparent_encoding
        html_text = resp.content.decode(encoding, errors="ignore")
        
        soup = BeautifulSoup(html_text, "lxml")
        rows = []
        for tr in soup.find_all("tr"):
            tds = tr.find_all("td")
            if not tds: continue
            rank, code, name = None, None, None
            txts = [td.get_text(strip=True) for td in tds]
            for s in txts:
                if rank is None and re.fullmatch(r"\d+", s): rank = int(s)
                elif rank and not code and re.fullmatch(r"\d{4}", s): code = s
                elif rank and code and not name and not re.fullmatch(r"\d+", s):
                    name = s; break
            if rank and code and name: rows.append({"æ’å": rank, "è‚¡ç¥¨ä»£ç¢¼": code, "è‚¡ç¥¨åç¨±": name})
            
        if not rows:
            dfs = pd.read_html(io.StringIO(html_text), flavor=["lxml", "html5lib"])
            for df in dfs:
                cols = "".join([str(c) for c in df.columns])
                if "æ’å" in cols and ("åç¨±" in cols or "ä»£è™Ÿ" in cols):
                    df.columns = [str(c).replace(" ", "") for c in df.columns]
                    col_map = {c: ("æ’å" if "æ’å" in c else "è‚¡ç¥¨ä»£ç¢¼" if "ä»£" in c else "è‚¡ç¥¨åç¨±") for c in df.columns if any(x in c for x in ["æ’å","ä»£","å"])}
                    df = df.rename(columns=col_map)
                    df = df[pd.to_numeric(df["æ’å"], errors='coerce').notnull()]
                    df["æ’å"] = df["æ’å"].astype(int)
                    df["è‚¡ç¥¨ä»£ç¢¼"] = df["è‚¡ç¥¨ä»£ç¢¼"].astype(str).str.extract(r'(\d{4})')[0]
                    return df.sort_values("æ’å").head(limit)
        return pd.DataFrame(rows).sort_values("æ’å").head(limit)
    except Exception as e:
        st.error(f"æŠ“å–å¸‚å€¼æ’åå¤±æ•—: {e}"); return pd.DataFrame()

@st.cache_data(ttl=3600)
def fetch_msci_list():
    """æŠ“å– MSCI æˆåˆ†è‚¡"""
    url = "https://stock.capital.com.tw/z/zm/zmd/zmdc.djhtm?MSCI=0"
    try:
        resp = requests.get(url, headers=HEADERS, timeout=20, verify=False)
        guess = chardet.detect(resp.content)
        encoding = guess['encoding'] if guess['encoding'] else 'cp950'
        html_text = resp.content.decode(encoding, errors="ignore")
        codes = set(re.findall(r"Link2Stk\('(\d{4})'\)", html_text))
        if not codes: codes = set(re.findall(r"\b(\d{4})\b", BeautifulSoup(html_text, "lxml").get_text()))
        return sorted(list(codes))
    except Exception as e:
        st.error(f"æŠ“å– MSCI åå–®å¤±æ•—: {e}"); return []

@st.cache_data(ttl=3600)
def fetch_0050_holdings():
    """æŠ“å– 0050 æˆåˆ†è‚¡"""
    url = "https://www.moneydj.com/ETF/X/Basic/Basic0007a.xdjhtm?etfid=0050.TW"
    try:
        resp = requests.get(url, headers=HEADERS, timeout=20, verify=False)
        resp.encoding = resp.apparent_encoding or "utf-8"
        dfs = pd.read_html(io.StringIO(resp.text), flavor="lxml")
        names = []
        for df in dfs:
            cols = [str(c[-1] if isinstance(df.columns, pd.MultiIndex) else c).strip() for c in df.columns]
            df.columns = cols
            target = next((c for c in cols if "åç¨±" in c), None)
            if target: names.extend(df[target].astype(str).str.strip().tolist())
        return pd.DataFrame({"è‚¡ç¥¨åç¨±": list(set([n for n in names if n not in ['nan','']]))})
    except Exception as e:
        st.error(f"æŠ“å– 0050 åå–®å¤±æ•—: {e}"); return pd.DataFrame()

@st.cache_data(ttl=300)
def get_stock_info(codes):
    """å–å¾—å³æ™‚è‚¡åƒ¹"""
    if not codes: return {}
    try:
        tickers = " ".join([f"{c}.TW" for c in codes])
        data = yf.Tickers(tickers)
        res = {}
        for c in codes:
            try:
                h = data.tickers[f"{c}.TW"].history(period="1d")
                if not h.empty:
                    res[c] = round(h["Close"].iloc[-1], 2)
                else:
                    res[c] = "-"
            except: res[c] = "-"
        return res
    except: return {}

# -------------------------------------------
# 3. æ—¥ç¨‹åˆ¤æ–·é‚è¼¯ (ä¿®æ­£ Bug)
# -------------------------------------------
def get_schedule_info():
    """è¨ˆç®—ä¸¦å›å‚³ MSCI èˆ‡ 0050 çš„æ—¥ç¨‹è³‡è¨Š"""
    today = date.today()
    m = today.month
    
    # è¼”åŠ©å‡½å¼ï¼šæ‰¾ä¸‹ä¸€å€‹ç™¼ç”Ÿçš„æœˆä»½
    def find_next_month(current, months):
        # å…ˆæ‰¾ä»Šå¹´é‚„æœ‰æ²’æœ‰å‰©ä¸‹çš„æœˆä»½
        candidates = [x for x in months if x >= current]
        if candidates:
            return candidates[0] # å¦‚æœæœ‰ï¼Œå–æœ€è¿‘çš„ä¸€å€‹
        else:
            return months[0] # å¦‚æœæ²’æœ‰ï¼Œå–æ˜å¹´çš„ç¬¬ä¸€å€‹

    # MSCI (2, 5, 8, 11æœˆ)
    next_msci = find_next_month(m, [2, 5, 8, 11])
    msci_info = {
        "next_month": next_msci,
        "announce": "è©²æœˆä¸­æ—¬ (ç´„10-15æ—¥)",
        "effective": "è©²æœˆæœˆåº•æ”¶ç›¤"
    }
    
    # 0050 (3, 6, 9, 12æœˆ)
    # ä¿®æ­£ï¼šè‹¥ç¾åœ¨æ˜¯ 11æœˆ, find_next_month æœƒå›å‚³ 12
    next_ftse = find_next_month(m, [3, 6, 9, 12])
    
    ftse_info = {
        "next_month": next_ftse,
        "announce": f"{next_ftse}æœˆ ç¬¬ä¸€å€‹æˆ–ç¬¬äºŒå€‹æ˜ŸæœŸäº”",
        "effective": f"{next_ftse}æœˆ ç¬¬ä¸‰å€‹æ˜ŸæœŸäº”æ”¶ç›¤"
    }
    return msci_info, ftse_info

# -------------------------------------------
# 4. ä¸»ä»‹é¢ UI
# -------------------------------------------

st.title("ğŸ“Š å°è‚¡æŒ‡æ•¸èª¿æ•´é æ¸¬æˆ°æƒ…å®¤")
st.caption("è³‡æ–™ä¾†æºï¼šæœŸäº¤æ‰€ (æ’å) | MoneyDJ (0050) | Yahoo Finance (è‚¡åƒ¹)")

# å´é‚Šæ¬„
with st.sidebar:
    st.header("âš™ï¸ è¨­å®šèˆ‡è³‡è¨Š")
    if st.button("ğŸ”„ å¼·åˆ¶æ›´æ–°è³‡æ–™"):
        st.cache_data.clear()
        st.rerun()
    
    st.info(f"æœ€å¾Œæ›´æ–°ï¼š{datetime.now().strftime('%H:%M')}")
    
    st.markdown("---")
    st.markdown("### ğŸ“… æŠ•è³‡è¡Œäº‹æ›†")
    msci_s, ftse_s = get_schedule_info()
    
    st.success(f"**0050 (å¯Œæ™‚) èª¿æ•´**\n\nä¸‹å›ï¼š**{ftse_s['next_month']}æœˆ**\nå…¬å¸ƒï¼š{ftse_s['announce']}\nç”Ÿæ•ˆï¼š{ftse_s['effective']}")
    st.info(f"**MSCI å­£åº¦èª¿æ•´**\n\nä¸‹å›ï¼š**{msci_s['next_month']}æœˆ**\nå…¬å¸ƒï¼š{msci_s['announce']}\nç”Ÿæ•ˆï¼š{msci_s['effective']}")

# æŠ“å–è³‡æ–™
with st.spinner("æ­£åœ¨åˆ†æå¤§ç›¤æ•¸æ“š..."):
    df_mcap = fetch_taifex_rankings()
    msci_codes = fetch_msci_list()
    df_0050 = fetch_0050_holdings()

if df_mcap.empty:
    st.error("ç„¡æ³•é€£ç·šè‡³æœŸäº¤æ‰€å–å¾—æ’åè³‡æ–™ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")
    st.stop()

tab1, tab2 = st.tabs(["ğŸ‡¹ğŸ‡¼ 0050 é—œéµæˆ°å½¹", "ğŸŒ MSCI å­£åº¦èª¿æ•´"])

# å…±ç”¨å‡½å¼ï¼šåŠ è‚¡åƒ¹
def add_price(df, codes_list):
    if df.empty: return df
    prices = get_stock_info(codes_list)
    df["ç¾åƒ¹"] = df["è‚¡ç¥¨ä»£ç¢¼"].map(lambda x: prices.get(x, "-"))
    return df

# ==========================================
# Tab 1: 0050
# ==========================================
with tab1:
    # ç­–ç•¥çœ‹æ¿
    st.markdown(f"""
    <div style="padding: 15px; background-color: #e6fffa; border-left: 5px solid #00b894; border-radius: 5px; margin-bottom: 20px;">
        <h4>ğŸ’¡ 0050 ä¸‹å›èª¿æ•´ï¼š{ftse_s['next_month']}æœˆ</h4>
        <ul>
            <li><b>è²·å…¥æ™‚æ©Ÿï¼š</b> {ftse_s['effective']} (ç”Ÿæ•ˆæ—¥) 13:25-13:30 è©¦æ“ç›¤ã€‚</li>
            <li><b>è¦å‰‡ï¼š</b> å¸‚å€¼å‰ 40 åã€Œå¿…ç„¶ç´å…¥ã€ï¼›60 åå¾Œã€Œå¿…ç„¶å‰”é™¤ã€ã€‚</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)

    if not df_0050.empty:
        current_0050 = set(df_0050["è‚¡ç¥¨åç¨±"].astype(str).str.strip())
        df_anl = df_mcap.head(100).copy()
        df_anl["in_0050"] = df_anl["è‚¡ç¥¨åç¨±"].isin(current_0050)
        
        # 1. å¿…ç„¶åˆ—å…¥ (<=40 & Not In)
        must_in = df_anl[(df_anl["æ’å"] <= 40) & (~df_anl["in_0050"])].copy()
        # 2. å¿…ç„¶å‰”é™¤ (>60 & In)
        in_list_stocks = df_mcap[df_mcap["è‚¡ç¥¨åç¨±"].isin(current_0050)]
        must_out = in_list_stocks[in_list_stocks["æ’å"] > 60].copy()
        # 3. æŒ‘æˆ°è€… (41~50)
        candidates = df_anl[(df_anl["æ’å"] > 40) & (df_anl["æ’å"] <= 50) & (~df_anl["in_0050"])].sort_values("æ’å").head(3)

        # æº–å‚™æŠ“è‚¡åƒ¹çš„æ¸…å–®
        all_codes = list(must_in["è‚¡ç¥¨ä»£ç¢¼"]) + list(candidates["è‚¡ç¥¨ä»£ç¢¼"]) + list(must_out["è‚¡ç¥¨ä»£ç¢¼"])
        prices = get_stock_info(all_codes)
        
        # é¡¯ç¤º
        st.subheader("ğŸš€ å¿…ç„¶ç´å…¥ (æ’å â‰¤ 40)")
        if not must_in.empty:
            must_in["ç¾åƒ¹"] = must_in["è‚¡ç¥¨ä»£ç¢¼"].map(lambda x: prices.get(x, "-"))
            st.success("ğŸ”¥ å¼·çƒˆè²·é€²è¨Šè™Ÿï¼ç¬¦åˆå¿…ç„¶ç´å…¥æ¨™æº–ã€‚")
            st.dataframe(must_in[["æ’å", "è‚¡ç¥¨ä»£ç¢¼", "è‚¡ç¥¨åç¨±", "ç¾åƒ¹"]], hide_index=True)
        else:
            st.info("ç›®å‰ç„¡å€‹è‚¡ç¬¦åˆå¿…ç„¶ç´å…¥æ¨™æº– (å‰ 40 åçš†å·²åœ¨åå–®å…§)ã€‚")
            
        st.divider()

        st.subheader("âš”ï¸ é—œéµæŒ‘æˆ°è€… (æ’å 41~50)")
        cols = st.columns(3)
        for i, (_, row) in enumerate(candidates.iterrows()):
            p = prices.get(row["è‚¡ç¥¨ä»£ç¢¼"], "-")
            with cols[i]:
                st.metric(f"No.{row['æ’å']} {row['è‚¡ç¥¨åç¨±']}", f"${p}", f"å·® {row['æ’å']-40} å", delta_color="inverse")
        
        st.divider()
        
        col_out, col_danger = st.columns(2)
        with col_out:
            st.subheader("ğŸ‘‹ å¿…ç„¶å‰”é™¤ (æ’å > 60)")
            if not must_out.empty:
                must_out["ç¾åƒ¹"] = must_out["è‚¡ç¥¨ä»£ç¢¼"].map(lambda x: prices.get(x, "-"))
                st.error("âš ï¸ é æœŸæœƒæœ‰è¢«å‹•è³£å£“")
                st.dataframe(must_out[["æ’å", "è‚¡ç¥¨ä»£ç¢¼", "è‚¡ç¥¨åç¨±", "ç¾åƒ¹"]], hide_index=True)
            else:
                st.write("ç„¡")
                
        with col_danger:
            st.subheader("âš ï¸ å±éšªé‚Šç·£ (41~60)")
            danger = in_list_stocks[(in_list_stocks["æ’å"] > 40) & (in_list_stocks["æ’å"] <= 60)].sort_values("æ’å", ascending=False)
            if not danger.empty:
                st.dataframe(danger[["æ’å", "è‚¡ç¥¨ä»£ç¢¼", "è‚¡ç¥¨åç¨±"]], hide_index=True)
            else:
                st.write("ç„¡")
    else:
        st.warning("ç„¡æ³•å–å¾— 0050 è³‡æ–™")

# ==========================================
# Tab 2: MSCI
# ==========================================
with tab2:
    # ç­–ç•¥çœ‹æ¿
    st.markdown(f"""
    <div style="padding: 15px; background-color: #fff8e6; border-left: 5px solid #fdcb6e; border-radius: 5px; margin-bottom: 20px;">
        <h4>ğŸ’¡ MSCI ä¸‹å›èª¿æ•´ï¼š{msci_s['next_month']}æœˆ</h4>
        <ul>
            <li><b>é—œéµå·®ç•°ï¼š</b> MSCI çœ‹é‡ã€Œè‡ªç”±æµé€šå¸‚å€¼ã€ï¼Œéå–®ç´”ç¸½å¸‚å€¼ã€‚</li>
            <li><b>é«˜æ©Ÿç‡ç´å…¥ï¼š</b> å¸‚å€¼è¡é€²å‰ <b>85</b> åä½†å°šæœªç´å…¥è€…ï¼Œæ©Ÿç‡æ¥µé«˜ã€‚</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)
    
    if msci_codes:
        # é‚è¼¯å„ªåŒ–ï¼š
        # 1. é«˜æ©Ÿç‡ç´å…¥ (High Probability): Rank <= 85 & Not in MSCI
        #    (å°ç£ MSCI æˆåˆ†è‚¡é€šå¸¸åœ¨ 88~90 æª”å·¦å³ï¼Œå– 85 æ˜¯å®‰å…¨é‚Šéš›)
        high_prob_in = df_mcap[(df_mcap["æ’å"] <= 85) & (~df_mcap["è‚¡ç¥¨ä»£ç¢¼"].isin(msci_codes))].copy()
        
        # 2. æ½›åœ¨è§€å¯Ÿ (Watch list): 86~100 å
        watch_in = df_mcap[(df_mcap["æ’å"] > 85) & (df_mcap["æ’å"] <= 100) & (~df_mcap["è‚¡ç¥¨ä»£ç¢¼"].isin(msci_codes))].copy()
        
        # 3. æ½›åœ¨å‰”é™¤
        pot_out = df_mcap[(df_mcap["æ’å"] > 100) & (df_mcap["è‚¡ç¥¨ä»£ç¢¼"].isin(msci_codes))].copy()

        # æŠ“è‚¡åƒ¹
        target_codes = list(high_prob_in["è‚¡ç¥¨ä»£ç¢¼"]) + list(pot_out["è‚¡ç¥¨ä»£ç¢¼"])
        prices = get_stock_info(target_codes)

        # é¡¯ç¤º
        st.subheader("ğŸ”¥ é«˜æ©Ÿç‡ç´å…¥åå–® (æ’å â‰¤ 85)")
        if not high_prob_in.empty:
            high_prob_in["ç¾åƒ¹"] = high_prob_in["è‚¡ç¥¨ä»£ç¢¼"].map(lambda x: prices.get(x, "-"))
            st.success("æ³¨æ„ï¼å¸‚å€¼å·²é” MSCI å®‰å…¨æ°´ä½ï¼Œç´å…¥æ©Ÿç‡é«˜ï¼")
            st.dataframe(high_prob_in[["æ’å", "è‚¡ç¥¨ä»£ç¢¼", "è‚¡ç¥¨åç¨±", "ç¾åƒ¹"]], hide_index=True)
        else:
            st.info("ç›®å‰å‰ 85 åçš†å·²åœ¨ MSCI åå–®å…§ï¼Œç„¡æ˜é¡¯æ¼ç¶²ä¹‹é­šã€‚")
            
        st.divider()
        
        c1, c2 = st.columns(2)
        with c1:
            st.subheader("ğŸš€ é‚Šç·£è§€å¯Ÿå€ (86~100)")
            st.dataframe(watch_in[["æ’å", "è‚¡ç¥¨ä»£ç¢¼", "è‚¡ç¥¨åç¨±"]], hide_index=True)
            
        with c2:
            st.subheader("âš ï¸ æ½›åœ¨å‰”é™¤é¢¨éšª (>100)")
            if not pot_out.empty:
                pot_out["ç¾åƒ¹"] = pot_out["è‚¡ç¥¨ä»£ç¢¼"].map(lambda x: prices.get(x, "-"))
                st.dataframe(pot_out[["æ’å", "è‚¡ç¥¨ä»£ç¢¼", "è‚¡ç¥¨åç¨±", "ç¾åƒ¹"]], hide_index=True)
            else:
                st.write("ç›®å‰ç„¡æ˜é¡¯å‰”é™¤é¢¨éšªå€‹è‚¡")
                
    else:
        st.warning("ç„¡æ³•å–å¾— MSCI åå–®")
